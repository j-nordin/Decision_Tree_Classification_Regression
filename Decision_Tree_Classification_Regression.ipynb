{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Introductory Tour and Decision Trees\n",
    "\n",
    "`Group`: PA 1 26\n",
    "\n",
    "`Date`: Januari 19, 2023\n",
    "\n",
    "`Group Members`:\n",
    "- Albin Ekström\n",
    "- Jonas Nordin\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: A classification example: fetal heart condition diagnosis\n",
    "\n",
    "In this task, the assignment was to condition fetal heart diagnosis by using different classifiers and determine which one gives the `best` accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 1: Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATA_FILE = \"data.csv\"\n",
    "\n",
    "# Read the CSV file.\n",
    "data = pd.read_csv(DATA_FILE, skiprows=1)\n",
    "\n",
    "# Select the relevant numerical columns.\n",
    "selected_cols = ['LB', 'AC', 'FM', 'UC', 'DL', 'DS', 'DP', 'ASTV', 'MSTV', 'ALTV',\n",
    "                 'MLTV', 'Width', 'Min', 'Max', 'Nmax', 'Nzeros', 'Mode', 'Mean',\n",
    "                 'Median', 'Variance', 'Tendency', 'NSP']\n",
    "data = data[selected_cols].dropna()\n",
    "\n",
    "# Shuffle the dataset.\n",
    "data_shuffled = data.sample(frac=1.0, random_state=0)\n",
    "\n",
    "# Split into input part X and output part Y.\n",
    "X = data_shuffled.drop('NSP', axis=1)\n",
    "\n",
    "# Map the diagnosis code to a human-readable label.\n",
    "def to_label(y):\n",
    "    return [None, 'normal', 'suspect', 'pathologic'][(int(y))]\n",
    "\n",
    "Y = data_shuffled['NSP'].apply(to_label)\n",
    "\n",
    "# Partition the data into training and test sets.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>DP</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>...</th>\n",
       "      <th>Width</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>134.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>109.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         LB   AC   FM   UC   DL   DS   DP  ASTV  MSTV  ALTV  ...  Width  \\\n",
       "658   130.0  1.0  0.0  3.0  0.0  0.0  0.0  24.0   1.2  12.0  ...   35.0   \n",
       "1734  134.0  9.0  1.0  8.0  5.0  0.0  0.0  59.0   1.2   0.0  ...  109.0   \n",
       "1226  125.0  1.0  0.0  4.0  0.0  0.0  0.0  43.0   0.7  31.0  ...   21.0   \n",
       "1808  143.0  0.0  0.0  1.0  0.0  0.0  0.0  69.0   0.3   6.0  ...   27.0   \n",
       "825   152.0  0.0  0.0  4.0  0.0  0.0  0.0  62.0   0.4  59.0  ...   25.0   \n",
       "\n",
       "        Min    Max  Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency  \n",
       "658   120.0  155.0   1.0     0.0  134.0  133.0   135.0       1.0       0.0  \n",
       "1734   80.0  189.0   6.0     0.0  150.0  146.0   150.0      33.0       0.0  \n",
       "1226  120.0  141.0   0.0     0.0  131.0  130.0   132.0       1.0       0.0  \n",
       "1808  132.0  159.0   1.0     0.0  145.0  144.0   146.0       1.0       0.0  \n",
       "825   136.0  161.0   0.0     0.0  159.0  156.0   158.0       1.0       1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data consisting of 21 numerical features\n",
    "X.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 2: Training the baseline classifier\n",
    "\n",
    "First, we create a dummy classifier to get a baseline accuracy. Then, to get an idea of how well our simple classifier works, we carry out cross-validation over the training set and compute the classification accuracy on each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78235294, 0.78235294, 0.77941176, 0.77941176, 0.77941176])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = DummyClassifier(strategy='most_frequent')\n",
    "cross_val_score(clf, Xtrain, Ytrain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Trying out some different classifiers\n",
    "\n",
    "In this step, we try out different classifiers and compare them to find wich gets the best cross-validation score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest score: [0.93529412 0.95588235 0.93529412 0.93529412 0.94117647]\n",
      "Decision tree score: [0.90294118 0.94411765 0.91176471 0.89705882 0.95      ]\n",
      "Gradient boosting score: [0.94117647 0.96176471 0.94411765 0.94411765 0.95294118]\n"
     ]
    }
   ],
   "source": [
    "# TREE-BASED CLASSIFIERS\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc_score = cross_val_score(rfc, Xtrain, Ytrain)\n",
    "print(\"Random forest score:\", rfc_score)\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc_score = cross_val_score(dtc, Xtrain, Ytrain)\n",
    "print(\"Decision tree score:\", dtc_score)\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc_score = cross_val_score(gbc, Xtrain, Ytrain)\n",
    "print(\"Gradient boosting score:\", gbc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron score:  [0.84705882 0.88529412 0.82941176 0.85294118 0.71176471]\n",
      "Logistic Regression score:  0.892018779342723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonasnordin/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jonasnordin/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jonasnordin/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jonasnordin/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC score:  [0.87352941 0.86764706 0.86176471 0.87058824 0.88823529]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonasnordin/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LINEAR CLASSIFIERS\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "per = Perceptron()\n",
    "per_score = cross_val_score(per, Xtrain, Ytrain)\n",
    "print(\"Perceptron score: \", per_score)\n",
    "\n",
    "lcr = LogisticRegression(max_iter = 40000)\n",
    "lcr.fit(Xtrain, Ytrain)\n",
    "# cross_val_score(LR, Xtrain, Ytrain) doesn't work???\n",
    "lcr_score = lcr.score(Xtest,Ytest)\n",
    "print(\"Logistic Regression score: \", lcr_score)\n",
    "\n",
    "svc = LinearSVC(max_iter=100_000)\n",
    "svc_score = cross_val_score(svc, Xtrain, Ytrain)\n",
    "print(\"Linear SVC score: \", svc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network score [0.88823529 0.89411765 0.84705882 0.89705882 0.85294118]\n"
     ]
    }
   ],
   "source": [
    "# NEUTRAL NETWORK CLASSIFIER\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nnc = MLPClassifier(hidden_layer_sizes=(100, 50, 25, 10, ))\n",
    "nnc_score = cross_val_score(nnc, Xtrain, Ytrain)\n",
    "print(\"Neural network score\", nnc_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Best performing classifier\n",
    "\n",
    "Gradient Boost classifier performed best of all classifiers. It works by combining multiple weak models to make a prediction. A sequence of decision trees is generated iteratively where each tree aims to reduce the residual errors made by the previous tree. The final prediction is made by averaging a prediction made (weighted) by the trees. To adjust the weights of each tree and feature, gradient descent is used to minimize the loss function with respect to the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost Classifier score:  0.9295774647887324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "  \n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "gbc.fit(Xtrain, Ytrain)\n",
    "Yguess = gbc.predict(Xtest)\n",
    "print(\"Gradient Boost Classifier score: \", accuracy_score(Ytest, Yguess))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Decision trees for classification\n",
    "\n",
    "In this task, the assignment was to use the premade TreeClassifier from Lecture 1 and find a max depth with good accuracy. Then, after finding a good accuracy a tree should be drawn, but `not` necessarily with the chosen max depth due to visibility. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imported code from lecture 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class DecisionTreeLeaf:\n",
    "\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    # This method computes the prediction for this leaf node. This will just return a constant value.\n",
    "    def predict(self, x):\n",
    "        return self.value\n",
    "\n",
    "    # Utility function to draw a tree visually using graphviz.\n",
    "    def draw_tree(self, graph, node_counter, names):\n",
    "        node_id = str(node_counter)\n",
    "        val_str = f'{self.value:.4g}' if isinstance(self.value, float) else str(self.value)\n",
    "        graph.node(node_id, val_str, style='filled')\n",
    "        return node_counter+1, node_id\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, DecisionTreeLeaf):\n",
    "            return self.value == other.value\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "class DecisionTreeBranch:\n",
    "\n",
    "    def __init__(self, feature, threshold, low_subtree, high_subtree):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.low_subtree = low_subtree\n",
    "        self.high_subtree = high_subtree\n",
    "\n",
    "    # For a branch node, we compute the prediction by first considering the feature, and then \n",
    "    # calling the upper or lower subtree, depending on whether the feature is or isn't greater\n",
    "    # than the threshold.\n",
    "    def predict(self, x):\n",
    "        if x[self.feature] <= self.threshold:\n",
    "            return self.low_subtree.predict(x)\n",
    "        else:\n",
    "            return self.high_subtree.predict(x)\n",
    "\n",
    "    # Utility function to draw a tree visually using graphviz.\n",
    "    def draw_tree(self, graph, node_counter, names):\n",
    "        node_counter, low_id = self.low_subtree.draw_tree(graph, node_counter, names)\n",
    "        node_counter, high_id = self.high_subtree.draw_tree(graph, node_counter, names)\n",
    "        node_id = str(node_counter)\n",
    "        fname = f'F{self.feature}' if names is None else names[self.feature]\n",
    "        lbl = f'{fname} > {self.threshold:.4g}?'\n",
    "        graph.node(node_id, lbl, shape='box', fillcolor='yellow', style='filled, rounded')\n",
    "        graph.edge(node_id, low_id, 'False')\n",
    "        graph.edge(node_id, high_id, 'True')\n",
    "        return node_counter+1, node_id\n",
    "\n",
    "\n",
    "from graphviz import Digraph\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class DecisionTree(ABC, BaseEstimator):\n",
    "\n",
    "    def __init__(self, max_depth):\n",
    "        super().__init__()\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    # As usual in scikit-learn, the training method is called *fit*. We first process the dataset so that\n",
    "    # we're sure that it's represented as a NumPy matrix. Then we call the recursive tree-building method\n",
    "    # called make_tree (see below).\n",
    "    def fit(self, X, Y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.names = X.columns\n",
    "            X = X.to_numpy()\n",
    "        elif isinstance(X, list):\n",
    "            self.names = None\n",
    "            X = np.array(X)\n",
    "        else:\n",
    "            self.names = None\n",
    "        Y = np.array(Y)        \n",
    "        self.root = self.make_tree(X, Y, self.max_depth)\n",
    "        \n",
    "    def draw_tree(self):\n",
    "        graph = Digraph()\n",
    "        self.root.draw_tree(graph, 0, self.names)\n",
    "        return graph\n",
    "    \n",
    "    # By scikit-learn convention, the method *predict* computes the classification or regression output\n",
    "    # for a set of instances.\n",
    "    # To implement it, we call a separate method that carries out the prediction for one instance.\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.to_numpy()\n",
    "        return [self.predict_one(x) for x in X]\n",
    "\n",
    "    # Predicting the output for one instance.\n",
    "    def predict_one(self, x):\n",
    "        return self.root.predict(x)        \n",
    "\n",
    "    # This is the recursive training \n",
    "    def make_tree(self, X, Y, max_depth):\n",
    "\n",
    "        # We start by computing the default value that will be used if we'll return a leaf node.\n",
    "        # For classifiers, this will be the most common value in Y.\n",
    "        default_value = self.get_default_value(Y)\n",
    "\n",
    "        # First the two base cases in the recursion: is the training set completely\n",
    "        # homogeneous, or have we reached the maximum depth? Then we need to return a leaf.\n",
    "\n",
    "        # If we have reached the maximum depth, return a leaf with the majority value.\n",
    "        if max_depth == 0:\n",
    "            return DecisionTreeLeaf(default_value)\n",
    "\n",
    "        # If all the instances in the remaining training set have the same output value,\n",
    "        # return a leaf with this value.\n",
    "        if self.is_homogeneous(Y):\n",
    "            return DecisionTreeLeaf(default_value)\n",
    "\n",
    "        # Select the \"most useful\" feature and split threshold. To rank the \"usefulness\" of features,\n",
    "        # we use one of the classification or regression criteria.\n",
    "        # For each feature, we call best_split (defined in a subclass). We then maximize over the features.\n",
    "        n_features = X.shape[1]\n",
    "        _, best_feature, best_threshold = max(self.best_split(X, Y, feature) for feature in range(n_features))\n",
    "        \n",
    "        if best_feature is None:\n",
    "            return DecisionTreeLeaf(default_value)\n",
    "\n",
    "        # Split the training set into subgroups, based on whether the selected feature is greater than\n",
    "        # the threshold or not\n",
    "        X_low, X_high, Y_low, Y_high = self.split_by_feature(X, Y, best_feature, best_threshold)\n",
    "\n",
    "        # Build the subtrees using a recursive call. Each subtree is associated\n",
    "        # with a value of the feature.\n",
    "        low_subtree = self.make_tree(X_low, Y_low, max_depth-1)\n",
    "        high_subtree = self.make_tree(X_high, Y_high, max_depth-1)\n",
    "\n",
    "        if low_subtree == high_subtree:\n",
    "            return low_subtree\n",
    "\n",
    "        # Return a decision tree branch containing the result.\n",
    "        return DecisionTreeBranch(best_feature, best_threshold, low_subtree, high_subtree)\n",
    "    \n",
    "    # Utility method that splits the data into the \"upper\" and \"lower\" part, based on a feature\n",
    "    # and a threshold.\n",
    "    def split_by_feature(self, X, Y, feature, threshold):\n",
    "        low = X[:,feature] <= threshold\n",
    "        high = ~low\n",
    "        return X[low], X[high], Y[low], Y[high]\n",
    "    \n",
    "    # The following three methods need to be implemented by the classification and regression subclasses.\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_default_value(self, Y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def is_homogeneous(self, Y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def best_split(self, X, Y, feature):\n",
    "        pass\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "class TreeClassifier(DecisionTree, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, max_depth=10, criterion='maj_sum'):\n",
    "        super().__init__(max_depth)\n",
    "        self.criterion = criterion\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        # For decision tree classifiers, there are some different ways to measure\n",
    "        # the homogeneity of subsets.\n",
    "        if self.criterion == 'maj_sum':\n",
    "            self.criterion_function = majority_sum_scorer\n",
    "        elif self.criterion == 'info_gain':\n",
    "            self.criterion_function = info_gain_scorer\n",
    "        elif self.criterion == 'gini':\n",
    "            self.criterion_function = gini_scorer\n",
    "        else:\n",
    "            raise Exception(f'Unknown criterion: {self.criterion}')\n",
    "        super().fit(X, Y)\n",
    "        self.classes_ = sorted(set(Y))\n",
    "\n",
    "    # Select a default value that is going to be used if we decide to make a leaf.\n",
    "    # We will select the most common value.\n",
    "    def get_default_value(self, Y):\n",
    "        self.class_distribution = Counter(Y)\n",
    "        return self.class_distribution.most_common(1)[0][0]\n",
    "    \n",
    "    # Checks whether a set of output values is homogeneous. In the classification case, \n",
    "    # this means that all output values are identical.\n",
    "    # We assume that we called get_default_value just before, so that we can access\n",
    "    # the class_distribution attribute. If the class distribution contains just one item,\n",
    "    # this means that the set is homogeneous.\n",
    "    def is_homogeneous(self, Y):\n",
    "        return len(self.class_distribution) == 1\n",
    "        \n",
    "    # Finds the best splitting point for a given feature. We'll keep frequency tables (Counters)\n",
    "    # for the upper and lower parts, and then compute the impurity criterion using these tables.\n",
    "    # In the end, we return a triple consisting of\n",
    "    # - the best score we found, according to the criterion we're using\n",
    "    # - the id of the feature\n",
    "    # - the threshold for the best split\n",
    "    def best_split(self, X, Y, feature):\n",
    "\n",
    "        # Create a list of input-output pairs, where we have sorted\n",
    "        # in ascending order by the input feature we're considering.\n",
    "        sorted_indices = np.argsort(X[:, feature])        \n",
    "        X_sorted = list(X[sorted_indices, feature])\n",
    "        Y_sorted = list(Y[sorted_indices])\n",
    "\n",
    "        n = len(Y)\n",
    "\n",
    "        # The frequency tables corresponding to the parts *before and including*\n",
    "        # and *after* the current element.\n",
    "        low_distr = Counter()\n",
    "        high_distr = Counter(Y)\n",
    "\n",
    "        # Keep track of the best result we've seen so far.\n",
    "        max_score = -np.inf\n",
    "        max_i = None\n",
    "\n",
    "        # Go through all the positions (excluding the last position).\n",
    "        for i in range(0, n-1):\n",
    "\n",
    "            # Input and output at the current position.\n",
    "            x_i = X_sorted[i]\n",
    "            y_i = Y_sorted[i]\n",
    "            \n",
    "            # Update the frequency tables.\n",
    "            low_distr[y_i] += 1\n",
    "            high_distr[y_i] -= 1\n",
    "\n",
    "            # If the input is equal to the input at the next position, we will\n",
    "            # not consider a split here.\n",
    "            #x_next = XY[i+1][0]\n",
    "            x_next = X_sorted[i+1]\n",
    "            if x_i == x_next:\n",
    "                continue\n",
    "\n",
    "            # Compute the homogeneity criterion for a split at this position.\n",
    "            score = self.criterion_function(i+1, low_distr, n-i-1, high_distr)\n",
    "\n",
    "            # If this is the best split, remember it.\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                max_i = i\n",
    "\n",
    "        # If we didn't find any split (meaning that all inputs are identical), return\n",
    "        # a dummy value.\n",
    "        if max_i is None:\n",
    "            return -np.inf, None, None\n",
    "\n",
    "        # Otherwise, return the best split we found and its score.\n",
    "        split_point = 0.5*(X_sorted[max_i] + X_sorted[max_i+1])\n",
    "        return max_score, feature, split_point\n",
    "\n",
    "def majority_sum_scorer(n_low, low_distr, n_high, high_distr):\n",
    "    maj_sum_low = low_distr.most_common(1)[0][1]\n",
    "    maj_sum_high = high_distr.most_common(1)[0][1]\n",
    "    return maj_sum_low + maj_sum_high\n",
    "    \n",
    "def entropy(distr):\n",
    "    n = sum(distr.values())\n",
    "    ps = [n_i/n for n_i in distr.values()]\n",
    "    return -sum(p*np.log2(p) if p > 0 else 0 for p in ps)\n",
    "\n",
    "def info_gain_scorer(n_low, low_distr, n_high, high_distr):\n",
    "    return -(n_low*entropy(low_distr)+n_high*entropy(high_distr))/(n_low+n_high)\n",
    "\n",
    "def gini_impurity(distr):\n",
    "    n = sum(distr.values())\n",
    "    ps = [n_i/n for n_i in distr.values()]\n",
    "    return 1-sum(p**2 for p in ps)\n",
    "    \n",
    "def gini_scorer(n_low, low_distr, n_high, high_distr):\n",
    "    return -(n_low*gini_impurity(low_distr)+n_high*gini_impurity(high_distr))/(n_low+n_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree classifier score (max_depth = 3): 0.9023529411764706\n",
      "Tree classifier score (max_depth = 4): 0.9105882352941176\n",
      "Tree classifier score (max_depth = 5): 0.9123529411764706\n",
      "Tree classifier score (max_depth = 13): 0.9135294117647058\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "max_v = 0.5\n",
    "for i in range(3, 25):\n",
    "    tcl = TreeClassifier(max_depth=i)\n",
    "    tcl_score = cross_val_score(tcl, Xtrain, Ytrain)\n",
    "    tcl_mean = np.mean(tcl_score)\n",
    "    if float(tcl_mean) > max_v:\n",
    "        max_v = tcl_mean\n",
    "        print(f\"Tree classifier score (max_depth = {i}):\", tcl_mean)\n",
    "\n",
    "# Best max depth: 13 (score: 0.9135294117647058) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 7.0.4 (20221203.1631)\n -->\n<!-- Pages: 1 -->\n<svg width=\"807pt\" height=\"305pt\"\n viewBox=\"0.00 0.00 807.49 305.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 301)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-301 803.49,-301 803.49,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"36.4\" cy=\"-18\" rx=\"36.29\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"36.4\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">suspect</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"138.4\" cy=\"-18\" rx=\"48.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"138.4\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">pathologic</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"yellow\" stroke=\"black\" d=\"M174.9,-123C174.9,-123 101.9,-123 101.9,-123 95.9,-123 89.9,-117 89.9,-111 89.9,-111 89.9,-99 89.9,-99 89.9,-93 95.9,-87 101.9,-87 101.9,-87 174.9,-87 174.9,-87 180.9,-87 186.9,-93 186.9,-99 186.9,-99 186.9,-111 186.9,-111 186.9,-117 180.9,-123 174.9,-123\"/>\n<text text-anchor=\"middle\" x=\"138.4\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">ASTV &gt; 79.5?</text>\n</g>\n<!-- 2&#45;&gt;0 -->\n<g id=\"edge1\" class=\"edge\">\n<title>2&#45;&gt;0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M117.76,-86.8C101.89,-73.58 79.87,-55.23 62.74,-40.95\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"65.37,-38.59 55.44,-34.87 60.88,-43.96 65.37,-38.59\"/>\n<text text-anchor=\"middle\" x=\"108.9\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2&#45;&gt;1 -->\n<g id=\"edge2\" class=\"edge\">\n<title>2&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M138.4,-86.8C138.4,-75.58 138.4,-60.67 138.4,-47.69\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"141.9,-47.98 138.4,-37.98 134.9,-47.98 141.9,-47.98\"/>\n<text text-anchor=\"middle\" x=\"151.4\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"240.4\" cy=\"-18\" rx=\"36.29\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"240.4\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">normal</text>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"342.4\" cy=\"-18\" rx=\"48.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"342.4\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">pathologic</text>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"yellow\" stroke=\"black\" d=\"M344.9,-123C344.9,-123 255.9,-123 255.9,-123 249.9,-123 243.9,-117 243.9,-111 243.9,-111 243.9,-99 243.9,-99 243.9,-93 249.9,-87 255.9,-87 255.9,-87 344.9,-87 344.9,-87 350.9,-87 356.9,-93 356.9,-99 356.9,-99 356.9,-111 356.9,-111 356.9,-117 350.9,-123 344.9,-123\"/>\n<text text-anchor=\"middle\" x=\"300.4\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">Tendency &gt; &#45;0.5?</text>\n</g>\n<!-- 5&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>5&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M288.25,-86.8C279.71,-74.7 268.13,-58.29 258.51,-44.65\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"261.41,-42.7 252.78,-36.55 255.69,-46.73 261.41,-42.7\"/>\n<text text-anchor=\"middle\" x=\"288.9\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 5&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>5&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M308.9,-86.8C314.65,-75.16 322.36,-59.55 328.94,-46.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"331.95,-48.05 333.24,-37.53 325.67,-44.95 331.95,-48.05\"/>\n<text text-anchor=\"middle\" x=\"337.4\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"yellow\" stroke=\"black\" d=\"M337.4,-210C337.4,-210 263.4,-210 263.4,-210 257.4,-210 251.4,-204 251.4,-198 251.4,-198 251.4,-186 251.4,-186 251.4,-180 257.4,-174 263.4,-174 263.4,-174 337.4,-174 337.4,-174 343.4,-174 349.4,-180 349.4,-186 349.4,-186 349.4,-198 349.4,-198 349.4,-204 343.4,-210 337.4,-210\"/>\n<text text-anchor=\"middle\" x=\"300.4\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">ALTV &gt; 68.5?</text>\n</g>\n<!-- 6&#45;&gt;2 -->\n<g id=\"edge5\" class=\"edge\">\n<title>6&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M267.22,-173.59C242.43,-160.59 208.33,-142.7 181.44,-128.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"183.35,-125.63 172.87,-124.09 180.1,-131.83 183.35,-125.63\"/>\n<text text-anchor=\"middle\" x=\"243.9\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 6&#45;&gt;5 -->\n<g id=\"edge6\" class=\"edge\">\n<title>6&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M300.4,-173.8C300.4,-162.58 300.4,-147.67 300.4,-134.69\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"303.9,-134.98 300.4,-124.98 296.9,-134.98 303.9,-134.98\"/>\n<text text-anchor=\"middle\" x=\"313.4\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"456.4\" cy=\"-18\" rx=\"48.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"456.4\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">pathologic</text>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"558.4\" cy=\"-18\" rx=\"36.29\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"558.4\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">normal</text>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"yellow\" stroke=\"black\" d=\"M495.9,-123C495.9,-123 424.9,-123 424.9,-123 418.9,-123 412.9,-117 412.9,-111 412.9,-111 412.9,-99 412.9,-99 412.9,-93 418.9,-87 424.9,-87 424.9,-87 495.9,-87 495.9,-87 501.9,-87 507.9,-93 507.9,-99 507.9,-99 507.9,-111 507.9,-111 507.9,-117 501.9,-123 495.9,-123\"/>\n<text text-anchor=\"middle\" x=\"460.4\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">Max &gt; 220.5?</text>\n</g>\n<!-- 9&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>9&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M459.59,-86.8C459.06,-75.58 458.36,-60.67 457.75,-47.69\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"461.26,-47.8 457.29,-37.98 454.26,-48.13 461.26,-47.8\"/>\n<text text-anchor=\"middle\" x=\"473.9\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 9&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>9&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M480.23,-86.8C495.24,-73.78 515.98,-55.79 532.33,-41.61\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"534.49,-44.37 539.75,-35.17 529.9,-39.08 534.49,-44.37\"/>\n<text text-anchor=\"middle\" x=\"528.4\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"649.4\" cy=\"-18\" rx=\"36.29\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"649.4\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">normal</text>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"751.4\" cy=\"-18\" rx=\"48.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"751.4\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">pathologic</text>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<path fill=\"yellow\" stroke=\"black\" d=\"M673.4,-123C673.4,-123 625.4,-123 625.4,-123 619.4,-123 613.4,-117 613.4,-111 613.4,-111 613.4,-99 613.4,-99 613.4,-93 619.4,-87 625.4,-87 625.4,-87 673.4,-87 673.4,-87 679.4,-87 685.4,-93 685.4,-99 685.4,-99 685.4,-111 685.4,-111 685.4,-117 679.4,-123 673.4,-123\"/>\n<text text-anchor=\"middle\" x=\"649.4\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">DP &gt; 1.5?</text>\n</g>\n<!-- 12&#45;&gt;10 -->\n<g id=\"edge9\" class=\"edge\">\n<title>12&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M649.4,-86.8C649.4,-75.58 649.4,-60.67 649.4,-47.69\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"652.9,-47.98 649.4,-37.98 645.9,-47.98 652.9,-47.98\"/>\n<text text-anchor=\"middle\" x=\"663.9\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 12&#45;&gt;11 -->\n<g id=\"edge10\" class=\"edge\">\n<title>12&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M670.04,-86.8C685.6,-73.83 707.1,-55.91 724.09,-41.76\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"725.9,-44.8 731.34,-35.71 721.42,-39.42 725.9,-44.8\"/>\n<text text-anchor=\"middle\" x=\"719.4\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<path fill=\"yellow\" stroke=\"black\" d=\"M498.9,-210C498.9,-210 421.9,-210 421.9,-210 415.9,-210 409.9,-204 409.9,-198 409.9,-198 409.9,-186 409.9,-186 409.9,-180 415.9,-174 421.9,-174 421.9,-174 498.9,-174 498.9,-174 504.9,-174 510.9,-180 510.9,-186 510.9,-186 510.9,-198 510.9,-198 510.9,-204 504.9,-210 498.9,-210\"/>\n<text text-anchor=\"middle\" x=\"460.4\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">Mean &gt; 107.5?</text>\n</g>\n<!-- 13&#45;&gt;9 -->\n<g id=\"edge11\" class=\"edge\">\n<title>13&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M460.4,-173.8C460.4,-162.58 460.4,-147.67 460.4,-134.69\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"463.9,-134.98 460.4,-124.98 456.9,-134.98 463.9,-134.98\"/>\n<text text-anchor=\"middle\" x=\"474.9\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 13&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>13&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M499.1,-173.59C529.08,-160.11 570.74,-141.38 602.59,-127.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"603.92,-130.29 611.61,-122.99 601.05,-123.9 603.92,-130.29\"/>\n<text text-anchor=\"middle\" x=\"579.4\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<path fill=\"yellow\" stroke=\"black\" d=\"M399.4,-297C399.4,-297 323.4,-297 323.4,-297 317.4,-297 311.4,-291 311.4,-285 311.4,-285 311.4,-273 311.4,-273 311.4,-267 317.4,-261 323.4,-261 323.4,-261 399.4,-261 399.4,-261 405.4,-261 411.4,-267 411.4,-273 411.4,-273 411.4,-285 411.4,-285 411.4,-291 405.4,-297 399.4,-297\"/>\n<text text-anchor=\"middle\" x=\"361.4\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">MSTV &gt; 0.45?</text>\n</g>\n<!-- 14&#45;&gt;6 -->\n<g id=\"edge13\" class=\"edge\">\n<title>14&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M349.05,-260.8C340.59,-249.01 329.2,-233.14 319.57,-219.72\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"322.49,-217.78 313.81,-211.7 316.8,-221.86 322.49,-217.78\"/>\n<text text-anchor=\"middle\" x=\"349.9\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 14&#45;&gt;13 -->\n<g id=\"edge14\" class=\"edge\">\n<title>14&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M381.43,-260.8C395.83,-248.44 415.45,-231.59 431.54,-217.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"433.6,-220.62 438.9,-211.45 429.04,-215.31 433.6,-220.62\"/>\n<text text-anchor=\"middle\" x=\"430.4\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fbb76769400>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw a tree with max depth 3\n",
    "tcl = TreeClassifier(max_depth=3)\n",
    "\n",
    "tcl.fit(Xtrain, Ytrain)\n",
    "tcl.draw_tree()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: A regression example: predicting apartment prices\n",
    "\n",
    "First, preprocessing of the data from sberbank.csv of apartment prices in Russia was made. Then, select a regression model based on the lowest score (closest to zero). Importing the mean squared error function from Sklearn is used to calculate the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the CSV file using Pandas.\n",
    "alldata = pd.read_csv(\"sberbank.csv\")\n",
    "\n",
    "# Convert the timestamp string to an integer representing the year.\n",
    "def get_year(timestamp):\n",
    "    return int(timestamp[:4])\n",
    "alldata['year'] = alldata.timestamp.apply(get_year)\n",
    "\n",
    "# Select the 9 input columns and the output column.\n",
    "selected_columns = ['price_doc', 'year', 'full_sq', 'life_sq', 'floor', 'num_room', 'kitch_sq', 'full_all']\n",
    "alldata = alldata[selected_columns]\n",
    "alldata = alldata.dropna()\n",
    "\n",
    "# Shuffle.\n",
    "alldata_shuffled = alldata.sample(frac=1.0, random_state=0)\n",
    "\n",
    "# Separate the input and output columns.\n",
    "X = alldata_shuffled.drop('price_doc', axis=1)\n",
    "# For the output, we'll use the log of the sales price.\n",
    "Y = alldata_shuffled['price_doc'].apply(np.log)\n",
    "\n",
    "# Split into training and test sets.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00278211, 0.00268078, 0.00342607, 0.00148416, 0.00126195]),\n",
       " 'score_time': array([0.00106692, 0.00062919, 0.00056505, 0.00037909, 0.000453  ]),\n",
       " 'test_score': array([-0.39897319, -0.37113485, -0.38083108, -0.39057156, -0.40475168])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using a baseline dummy regressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "m1 = DummyRegressor()\n",
    "cross_validate(m1, Xtrain, Ytrain, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression score:  [-0.30222063 -0.32537384 -0.29377903 -0.29296258 -0.29265721]\n",
      "Ridge regression score:  [-0.30222063 -0.32537046 -0.29377831 -0.29296256 -0.29265724]\n",
      "Linear regression score:  [-0.31042005 -0.29379119 -0.29803599 -0.30061325 -0.30237486]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "  \n",
    "\n",
    "LR = LinearRegression()\n",
    "LR.fit(Xtrain, Ytrain)\n",
    "lr_score = cross_validate(LR, Xtrain, Ytrain, scoring='neg_mean_squared_error')['test_score']\n",
    "print(\"Linear regression score: \", lr_score)\n",
    "\n",
    "R = Ridge()\n",
    "R.fit(Xtrain, Ytrain)\n",
    "r_score = cross_validate(R, Xtrain, Ytrain, scoring='neg_mean_squared_error')['test_score']\n",
    "print(\"Ridge regression score: \", r_score)\n",
    "\n",
    "L = Lasso()\n",
    "L.fit(Xtrain, Ytrain)\n",
    "l_score = cross_validate(L, Xtrain, Ytrain, scoring='neg_mean_squared_error')['test_score']\n",
    "print(\"Linear regression score: \", l_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest score:  [-0.29312902 -0.27803908 -0.27766253 -0.2810837  -0.28837561]\n",
      "Decision Tree score:  [-0.53728212 -0.52379181 -0.49924309 -0.51167511 -0.5646694 ]\n",
      "Gradient boosting score:  [-0.27650388 -0.24920729 -0.26294248 -0.27079364 -0.26330243]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "rfc = RandomForestRegressor()\n",
    "rfc.fit(Xtrain, Ytrain)\n",
    "rfc_score = cross_validate(rfc, Xtrain, Ytrain, scoring='neg_mean_squared_error')['test_score']\n",
    "print(\"Random Forest score: \", rfc_score)\n",
    "\n",
    "dtc = DecisionTreeRegressor()\n",
    "dtc.fit(Xtrain, Ytrain)\n",
    "dtc_score = cross_validate(dtc, Xtrain, Ytrain, scoring='neg_mean_squared_error')['test_score']\n",
    "print(\"Decision Tree score: \", dtc_score)\n",
    "\n",
    "gbc = GradientBoostingRegressor()\n",
    "gbc.fit(Xtrain, Ytrain)\n",
    "gbc_score = cross_validate(gbc, Xtrain, Ytrain, scoring='neg_mean_squared_error')['test_score']\n",
    "print(\"Gradient boosting score: \", gbc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor score:  [   -7.45699167  -222.77169322    -9.00663714   -19.28751534\n",
      " -3943.30408336]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "MLP = MLPRegressor()\n",
    "MLP.fit(Xtrain, Ytrain)\n",
    "mlp_score = cross_validate(MLP, Xtrain, Ytrain, scoring='neg_mean_squared_error')['test_score']\n",
    "print(\"MLPRegressor score: \", mlp_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost Regression\n",
    "Gradient boost regressor got the `best score of negative-MSE approximately -0.2492 `.\n",
    "\n",
    "The gradient boost regression algorithm works the same as the classifier algorithm, but with the difference that the target variable is continuous (e.g. predicting a house price on its features). Both methods use gradient descent to minimize the loss function allowing the model to learn from previous mistakes and improve the accuracy of the final predictions. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Decision trees for regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task a TreeRegressor is implemented and used to predict house prices. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Implementing the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast version of calculation the varience of a distribution\n",
    "def fast_var(set):\n",
    "    n = len(set)\n",
    "    return sum([x**2 for x in set])/n - (sum(set)**2)/(n**2)\n",
    "\n",
    "# The function of variance reduction\n",
    "def variance_reduction(n_low, low_distr, n_high, high_distr):\n",
    "    total_var = fast_var(np.hstack((low_distr, high_distr)))\n",
    "    high_term = (n_high*fast_var(high_distr))/(n_low+n_high)\n",
    "    low_term = (n_low*fast_var(low_distr))/(n_low+n_high)\n",
    "    return total_var - high_term - low_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "class TreeRegressor(DecisionTree, RegressorMixin):\n",
    "    \n",
    "    def __init__(self, max_depth=10, criterion='variance_reduction'):\n",
    "        super().__init__(max_depth)\n",
    "        self.criterion = criterion\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        # For decision tree classifiers, there are some different ways to measure\n",
    "        # the homogeneity of subsets.\n",
    "        if self.criterion == 'maj_sum':\n",
    "            self.criterion_function = majority_sum_scorer\n",
    "        elif self.criterion == 'info_gain':\n",
    "            self.criterion_function = info_gain_scorer\n",
    "        elif self.criterion == 'gini':\n",
    "            self.criterion_function = gini_scorer\n",
    "        elif self.criterion == 'variance_reduction':\n",
    "                self.criterion_function = variance_reduction\n",
    "        else:\n",
    "            raise Exception(f'Unknown criterion: {self.criterion}')\n",
    "        super().fit(X, Y)\n",
    "        self.classes_ = sorted(set(Y))\n",
    "\n",
    "    # Select a default value that is going to be used if we decide to make a leaf.\n",
    "    # We will select the most common value.\n",
    "    def get_default_value(self, Y):\n",
    "        mean_value = np.mean(Y)\n",
    "        return mean_value\n",
    "    \n",
    "    # Checks whether a set of output values is homogeneous. In the classification case, \n",
    "    # this means that all output values are identical.\n",
    "    # We assume that we called get_default_value just before, so that we can access\n",
    "    # the class_distribution attribute. If the class distribution contains just one item,\n",
    "    # this means that the set is homogeneous.\n",
    "    def is_homogeneous(self, Y):\n",
    "        threshold = 0.1\n",
    "        return np.var(Y) < threshold\n",
    "        \n",
    "    # Finds the best splitting point for a given feature. We'll keep frequency tables (Counters)\n",
    "    # for the upper and lower parts, and then compute the impurity criterion using these tables.\n",
    "    # In the end, we return a triple consisting of\n",
    "    # - the best score we found, according to the criterion we're using\n",
    "    # - the id of the feature\n",
    "    # - the threshold for the best split\n",
    "    def best_split(self, X, Y, feature):\n",
    "\n",
    "        # Create a list of input-output pairs, where we have sorted\n",
    "        # in ascending order by the input feature we're considering.\n",
    "        sorted_indices = np.argsort(X[:, feature])        \n",
    "        X_sorted = list(X[sorted_indices, feature])\n",
    "        Y_sorted = list(Y[sorted_indices])\n",
    "\n",
    "        n = len(Y)\n",
    "\n",
    "        # The frequency tables corresponding to the parts *before and including*\n",
    "        # and *after* the current element.\n",
    "        low_distr = []\n",
    "        high_distr = Y_sorted\n",
    "\n",
    "        # Keep track of the best result we've seen so far.\n",
    "        max_score = -np.inf\n",
    "        max_i = None\n",
    "\n",
    "        # Go through all the positions (excluding the last position).\n",
    "        for i in range(0, n-1):\n",
    "            # Update the frequency tables.\n",
    "            low_distr = Y_sorted[0:i+1]\n",
    "            high_distr = Y_sorted[i+1:]\n",
    "\n",
    "            # If the input is equal to the input at the next position, we will\n",
    "            # not consider a split here.\n",
    "            #x_next = XY[i+1][0]\n",
    "            x_next = X_sorted[i+1]\n",
    "            if X_sorted[i] == x_next:\n",
    "                continue\n",
    "\n",
    "            # Compute the homogeneity criterion for a split at this position.\n",
    "            score = self.criterion_function(i+1, low_distr, n-i-1, high_distr)\n",
    "\n",
    "            # If this is the best split, remember it.\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                max_i = i\n",
    "\n",
    "        # If we didn't find any split (meaning that all inputs are identical), return\n",
    "        # a dummy value.\n",
    "        if max_i is None:\n",
    "            return -np.inf, None, None\n",
    "\n",
    "        # Otherwise, return the best split we found and its score.\n",
    "        split_point = 0.5*(X_sorted[max_i] + X_sorted[max_i+1])\n",
    "        return max_score, feature, split_point\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Sanity check\n",
    "\n",
    "`Hypothesise` would be to have a decision tree of depth `one` because then the data can be separated in a split and the residual error will be small. There's no idea to have more than one in max depth because more splits wouldn't lower the residual error. With a max depth of `zero` the split would make an average of all data points. This would be a good approximation, but give a relatively large residual error compared to max depth of `one`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_some_data(n):\n",
    "    x = np.random.uniform(-5, 5, size=n)\n",
    "    Y = (x > 1) + 0.1*np.random.normal(size=n)\n",
    "    X = x.reshape(n, 1) # X needs to be a 2-dimensional matrix\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree regression score:  0.01115020661194649\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 7.0.4 (20221203.1631)\n -->\n<!-- Pages: 1 -->\n<svg width=\"190pt\" height=\"131pt\"\n viewBox=\"0.00 0.00 189.89 131.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 127)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-127 185.89,-127 185.89,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"46.8\" cy=\"-18\" rx=\"46.59\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"46.8\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">&#45;0.002306</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"146.8\" cy=\"-18\" rx=\"35.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"146.8\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">0.9954</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"yellow\" stroke=\"black\" d=\"M126.3,-123C126.3,-123 67.3,-123 67.3,-123 61.3,-123 55.3,-117 55.3,-111 55.3,-111 55.3,-99 55.3,-99 55.3,-93 61.3,-87 67.3,-87 67.3,-87 126.3,-87 126.3,-87 132.3,-87 138.3,-93 138.3,-99 138.3,-99 138.3,-111 138.3,-111 138.3,-117 132.3,-123 126.3,-123\"/>\n<text text-anchor=\"middle\" x=\"96.8\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">F0 &gt; 1.054?</text>\n</g>\n<!-- 2&#45;&gt;0 -->\n<g id=\"edge1\" class=\"edge\">\n<title>2&#45;&gt;0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M86.68,-86.8C79.72,-74.97 70.34,-59.03 62.43,-45.58\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"65.58,-44.03 57.5,-37.19 59.55,-47.58 65.58,-44.03\"/>\n<text text-anchor=\"middle\" x=\"89.3\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2&#45;&gt;1 -->\n<g id=\"edge2\" class=\"edge\">\n<title>2&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106.91,-86.8C113.92,-74.89 123.37,-58.82 131.32,-45.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"134.21,-47.3 136.27,-36.9 128.18,-43.75 134.21,-47.3\"/>\n<text text-anchor=\"middle\" x=\"136.8\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fbb54fa0160>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train our desicion tree on a small generated dataset\n",
    "generated_data = make_some_data(100)\n",
    "\n",
    "plt.scatter(generated_data[0], generated_data[1])\n",
    "\n",
    "tr = TreeRegressor(max_depth=1)\n",
    "tr.fit(generated_data[0], generated_data[1])\n",
    "\n",
    "\n",
    "tr_score = mean_squared_error(generated_data[1], tr.predict(generated_data[0]))\n",
    "print(\"Tree regression score: \", tr_score)\n",
    "\n",
    "tr.draw_tree()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Predicting apartment prices using decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = TreeRegressor(max_depth=10)\n",
    "tr.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree regression score with a max depth of 10:  0.31335604177475485\n"
     ]
    }
   ],
   "source": [
    "tr_score = mean_squared_error(Ytest, tr.predict(Xtest))\n",
    "print(\"Tree regression score with a max depth of 10: \", tr_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree regression scored with max depth 0, training - 0.3891468647585388, test - 0.4028398414133475\n",
      "Tree regression scored with max depth 1, training - 0.3263543480100574, test - 0.34098250711388134\n",
      "Tree regression scored with max depth 2, training - 0.30042490282992007, test - 0.3116427403885958\n",
      "Tree regression scored with max depth 3, training - 0.28927232915183554, test - 0.30188395972140913\n",
      "Tree regression scored with max depth 4, training - 0.2807451934658121, test - 0.29310031188060437\n",
      "Tree regression scored with max depth 5, training - 0.2742861310363099, test - 0.2908261342315253\n",
      "Tree regression scored with max depth 6, training - 0.2667434009364825, test - 0.28643634372540716\n",
      "Tree regression scored with max depth 7, training - 0.2580975870702128, test - 0.2903456812456766\n",
      "Tree regression scored with max depth 8, training - 0.24871134720458812, test - 0.29958287041487663\n",
      "Tree regression scored with max depth 9, training - 0.2399212618132105, test - 0.30619762526665\n",
      "Tree regression scored with max depth 10, training - 0.22830762290316794, test - 0.31335604177475485\n",
      "Tree regression scored with max depth 11, training - 0.21575688242870109, test - 0.32121930059606496\n",
      "Tree regression scored with max depth 12, training - 0.20319241737696103, test - 0.3362578868078887\n"
     ]
    }
   ],
   "source": [
    "max_depths = range(0,13)\n",
    "test_scores = []\n",
    "training_scores = []\n",
    "\n",
    "for i in max_depths:\n",
    "    tr = TreeRegressor(max_depth=i)\n",
    "    tr.fit(Xtrain, Ytrain)\n",
    "\n",
    "    training_score = mean_squared_error(Ytrain, tr.predict(Xtrain))\n",
    "    test_score = mean_squared_error(Ytest, tr.predict(Xtest))\n",
    "\n",
    "    training_scores.append(training_score)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "    print(f\"Tree regression scored with max depth {i}, training - {training_score}, test - {test_score}\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Outcome` from the evaluation score on the `training set` and on the `test set` for different values of `max_depth`:\n",
    "\n",
    "Tree regression scored with max depth 0,  training - 0.3891468647585388,   test - 0.4028398414133475\n",
    "\n",
    "Tree regression scored with max depth 1,  training - 0.3263543480100574,   test - 0.34098250711388134\n",
    "\n",
    "Tree regression scored with max depth 2,  training - 0.30042490282992007,  test - 0.3116427403885958\n",
    "\n",
    "Tree regression scored with max depth 3,  training - 0.28927232915183554,  test - 0.30188395972140913\n",
    "\n",
    "Tree regression scored with max depth 4,  training - 0.2807451934658121,   test - 0.29310031188060437\n",
    "\n",
    "Tree regression scored with max depth 5,  training - 0.2742861310363099,   test - 0.2908261342315253\n",
    "\n",
    "Tree regression scored with max depth 6,  training - 0.2667434009364825,   test - 0.28643634372540716\n",
    "\n",
    "Tree regression scored with max depth 7,  training - 0.2580975870702128,   test - 0.2903456812456766\n",
    "\n",
    "Tree regression scored with max depth 8,  training - 0.24871134720458812,  test - 0.29958287041487663\n",
    "\n",
    "Tree regression scored with max depth 9,  training - 0.2399212618132105,   test - 0.30619762526665\n",
    "\n",
    "Tree regression scored with max depth 10, training - 0.22830762290316794, test - 0.31335604177475485\n",
    "\n",
    "Tree regression scored with max depth 11, training - 0.21575688242870109, test - 0.32121930059606496\n",
    "\n",
    "Tree regression scored with max depth 12, training - 0.20319241737696103, test - 0.3362578868078887"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(max_depths, test_scores, '-o', label=\"Test scores\")\n",
    "plt.plot(max_depths, training_scores, '-o', label=\"Training scores\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the two curves start by following each other until the max depth reaches 6. After this point, the test scores start rising while the training score falls even faster. This indicated that the model starts to overfit the data. Therefore the best value to use as a max depth, in this case, would be 6 as this gives us the best score on the test set while not being too overfit to the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e2fb0d209027be7d534b282a1d38ea523e65ed3f0187f418bd1d8276918de21e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
